{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers.read_dataset import *\n",
    "from scipy.stats import entropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "adult = read_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def score(data, option):\n",
    "    return data.value_counts()[option] / 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def exponential(x, R, u, sensitivity, epsilon):  # per https://programming-dp.com/ch9.html#the-exponential-mechanism-for-finite-sets\n",
    "    # Calculate the score for each element of R:\n",
    "    scores = [u(x, r) for r in R]\n",
    "\n",
    "    # Calculate the probability for each element, based on its score:\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "\n",
    "    # Normalize the probabilities so they sum to 1:\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities:\n",
    "    return np.random.choice(R, 1, p=probabilities)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate 1,000 results for the query over each of three other datasets, with $\\epsilon=1$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'original': adult,\n",
    "    'sans_1st_freq': adult.drop(index=\n",
    "        adult[adult['education'] == adult['education'].value_counts().keys()[0]].first_valid_index()\n",
    "    ),  # removing a record with the most frequent \"Education\".\n",
    "    'sans_2nd_freq': adult.drop(index=\n",
    "        adult[adult['education'] == adult['education'].value_counts().keys()[1]].index\n",
    "    ), # removing any record  with the second most frequent \"Education\".\n",
    "    'sans_1st_infr': adult.drop(index=\n",
    "        adult[adult['education'] == adult['education'].value_counts().keys()[-1]].index\n",
    "    ) # removing any record with the least frequent \"Education\".\n",
    "}\n",
    "\n",
    "# Generate 1,000 results of the query for each group:\n",
    "results = {\n",
    "    group_name: pd.Series([exponential(group_data['education'], group_data['education'].unique(), score, 1, 1) for i in range(1000)]).value_counts()\n",
    "    for group_name, group_data in groups.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the results into a csv file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('hw1-ii-7.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define validation measure:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def validate_group(group_name, epsilon):\n",
    "    # Calculate frequency of each %.2f result (bin):\n",
    "    orig_freq = results['original']\n",
    "    nebr_freq = results[group_name]\n",
    "\n",
    "    # Keep only the common categories:\n",
    "    common_keys = nebr_freq[np.nan_to_num(nebr_freq) != 0].keys()\n",
    "    orig_v = orig_freq[common_keys]\n",
    "    nebr_v = nebr_freq[common_keys]\n",
    "\n",
    "    return entropy(orig_v, nebr_v) < epsilon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the check for all 3 groups:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sans_1st_freq': True, 'sans_2nd_freq': True, 'sans_1st_infr': True}\n"
     ]
    }
   ],
   "source": [
    "print({name: validate_group(name, 0.5) for name in ['sans_1st_freq', 'sans_2nd_freq', 'sans_1st_infr']})"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
